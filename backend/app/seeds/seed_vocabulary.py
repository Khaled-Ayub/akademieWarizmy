"""
Seed-Skript fÃ¼r Vokabellisten
LÃ¤dt die vordefinierten Vokabeln aus vocabulary_data.json in die Datenbank
"""

import json
import os
import asyncio
import re
import unicodedata
from pathlib import Path
from datetime import datetime

# Pfad zur aktuellen Datei
CURRENT_DIR = Path(__file__).parent
DATA_FILE = CURRENT_DIR / "vocabulary_data.json"


def generate_slug(text: str) -> str:
    """Generiert einen URL-freundlichen Slug"""
    # Umlaute ersetzen
    replacements = {
        'Ã¤': 'ae', 'Ã¶': 'oe', 'Ã¼': 'ue', 'ÃŸ': 'ss',
        'Ã„': 'Ae', 'Ã–': 'Oe', 'Ãœ': 'Ue'
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    # Unicode normalisieren und nicht-ASCII entfernen
    text = unicodedata.normalize('NFKD', text)
    text = text.encode('ascii', 'ignore').decode('ascii')
    
    # Kleinbuchstaben und Sonderzeichen durch Bindestriche ersetzen
    text = text.lower()
    text = re.sub(r'[^a-z0-9]+', '-', text)
    text = text.strip('-')
    
    return text


async def seed_vocabulary():
    """LÃ¤dt alle Vokabellisten in die Datenbank"""
    
    # Imports hier, um Circular-Imports zu vermeiden
    from app.db.session import AsyncSessionLocal
    from app.models.vocabulary.vocabulary import (
        VocabularyList, VocabularyItem, 
        WordType, NounCategory, VocabularyLevel
    )
    from sqlalchemy import select, delete
    
    # JSON-Daten laden
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    async with AsyncSessionLocal() as session:
        try:
            # Alte Daten lÃ¶schen (optional - auskommentieren wenn nicht gewÃ¼nscht)
            # await session.execute(delete(VocabularyItem))
            # await session.execute(delete(VocabularyList))
            # await session.commit()
            
            lists_created = 0
            items_created = 0
            
            # ========================================
            # 1. Nomen-Listen nach Kategorien erstellen
            # ========================================
            category_mapping = {
                "family": ("Familie", "Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©", NounCategory.FAMILY),
                "social": ("Soziale Kontakte", "Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©", NounCategory.GENERAL),
                "adjectives": ("Adjektive", "Ø§Ù„ØµÙØ§Øª", NounCategory.GENERAL),
                "school": ("Schule & UniversitÃ¤t", "Ø§Ù„Ù…Ø¯Ø±Ø³Ø© ÙˆØ§Ù„Ø¬Ø§Ù…Ø¹Ø©", NounCategory.SCHOOL),
                "colors": ("Farben", "Ø§Ù„Ø£Ù„ÙˆØ§Ù†", NounCategory.COLORS),
                "astronomy": ("Astronomie & Natur", "Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„Ø·Ø¨ÙŠØ¹Ø©", NounCategory.NATURE),
                "environment": ("Umfeld & Bildung", "Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…", NounCategory.GENERAL),
                "time": ("Zeit & Tageszeiten", "Ø§Ù„ÙˆÙ‚Øª ÙˆØ£ÙˆÙ‚Ø§Øª Ø§Ù„ÙŠÙˆÙ…", NounCategory.TIME),
                "grammar": ("Grammatik-Fachbegriffe", "Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù†Ø­Ùˆ", NounCategory.GENERAL),
            }
            
            for cat_key, nouns in data.get("nouns", {}).items():
                if cat_key in category_mapping:
                    title, title_ar, noun_cat = category_mapping[cat_key]
                    slug = generate_slug(title)
                    
                    # PrÃ¼fen ob Liste bereits existiert
                    existing = await session.execute(
                        select(VocabularyList).where(VocabularyList.slug == slug)
                    )
                    if existing.scalar_one_or_none():
                        print(f"  â­ï¸  Liste '{title}' existiert bereits, Ã¼berspringe...")
                        continue
                    
                    # Neue Liste erstellen
                    vocab_list = VocabularyList(
                        title=title,
                        title_arabic=title_ar,
                        slug=slug,
                        description=f"Arabische Vokabeln zum Thema {title}",
                        word_type=WordType.NOUN,
                        noun_category=noun_cat,
                        level=VocabularyLevel.A1,
                        is_published=True,
                        item_count=len(nouns),
                        tags=[cat_key, "nomen", "grundwortschatz"],
                    )
                    session.add(vocab_list)
                    await session.flush()
                    
                    # Vokabeln hinzufÃ¼gen
                    for idx, noun in enumerate(nouns):
                        item = VocabularyItem(
                            vocabulary_list_id=vocab_list.id,
                            arabic=noun["arabic"],
                            arabic_voweled=noun["arabic"],
                            german=noun["german"],
                            word_type=WordType.NOUN,
                            order=idx + 1,
                            difficulty=1,
                            is_verified=True,
                        )
                        session.add(item)
                        items_created += 1
                    
                    lists_created += 1
                    print(f"  âœ… Liste '{title}' mit {len(nouns)} Vokabeln erstellt")
            
            # ========================================
            # 2. Verben-Liste erstellen
            # ========================================
            verbs = data.get("verbs", [])
            if verbs:
                slug = "arabische-verben-grundwortschatz"
                
                existing = await session.execute(
                    select(VocabularyList).where(VocabularyList.slug == slug)
                )
                if not existing.scalar_one_or_none():
                    verb_list = VocabularyList(
                        title="Arabische Verben - Grundwortschatz",
                        title_arabic="Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                        slug=slug,
                        description="Wichtige arabische Verben mit Vergangenheit und Gegenwart",
                        word_type=WordType.VERB,
                        level=VocabularyLevel.A1,
                        is_published=True,
                        item_count=len(verbs),
                        tags=["verben", "grundwortschatz", "konjugation"],
                    )
                    session.add(verb_list)
                    await session.flush()
                    
                    for idx, verb in enumerate(verbs):
                        # Verb-Format: "past â€“ present"
                        arabic_parts = verb["arabic"].split(" â€“ ")
                        past_tense = arabic_parts[0] if len(arabic_parts) > 0 else verb["arabic"]
                        present_tense = arabic_parts[1] if len(arabic_parts) > 1 else ""
                        
                        item = VocabularyItem(
                            vocabulary_list_id=verb_list.id,
                            arabic=verb["arabic"],
                            arabic_voweled=verb["arabic"],
                            german=verb["german"],
                            word_type=WordType.VERB,
                            past_tense=past_tense,
                            present_tense=present_tense,
                            verb_form=verb.get("pattern", ""),
                            order=idx + 1,
                            difficulty=2,
                            is_verified=True,
                        )
                        session.add(item)
                        items_created += 1
                    
                    lists_created += 1
                    print(f"  âœ… Verben-Liste mit {len(verbs)} Verben erstellt")
                else:
                    print("  â­ï¸  Verben-Liste existiert bereits, Ã¼berspringe...")
            
            # ========================================
            # 3. Partikel-Listen erstellen
            # ========================================
            particles = data.get("particles", {})
            particle_categories = {
                "genitive": ("PrÃ¤positionen (Genitiv)", "Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±"),
                "conjunction": ("Konjunktionen", "Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø·Ù"),
                "interrogative": ("FragewÃ¶rter", "Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…"),
                "negation": ("Negationspartikel", "Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù†ÙÙŠ"),
                "demonstrative": ("Demonstrativpronomen", "Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"),
            }
            
            for part_key, items in particles.items():
                if part_key in particle_categories:
                    title, title_ar = particle_categories[part_key]
                    slug = generate_slug(title)
                    
                    existing = await session.execute(
                        select(VocabularyList).where(VocabularyList.slug == slug)
                    )
                    if existing.scalar_one_or_none():
                        print(f"  â­ï¸  Liste '{title}' existiert bereits, Ã¼berspringe...")
                        continue
                    
                    part_list = VocabularyList(
                        title=title,
                        title_arabic=title_ar,
                        slug=slug,
                        description=f"Arabische {title}",
                        word_type=WordType.PARTICLE,
                        level=VocabularyLevel.A1,
                        is_published=True,
                        item_count=len(items),
                        tags=["partikel", part_key, "grammatik"],
                    )
                    session.add(part_list)
                    await session.flush()
                    
                    for idx, item_data in enumerate(items):
                        item = VocabularyItem(
                            vocabulary_list_id=part_list.id,
                            arabic=item_data["arabic"],
                            arabic_voweled=item_data["arabic"],
                            german=item_data["german"],
                            word_type=WordType.PARTICLE,
                            order=idx + 1,
                            difficulty=1,
                            is_verified=True,
                        )
                        session.add(item)
                        items_created += 1
                    
                    lists_created += 1
                    print(f"  âœ… Liste '{title}' mit {len(items)} Partikeln erstellt")
            
            # ========================================
            # 4. Antonyme-Liste erstellen
            # ========================================
            antonyms = data.get("antonyms", [])
            if antonyms:
                slug = "antonyme-gegenteile"
                
                existing = await session.execute(
                    select(VocabularyList).where(VocabularyList.slug == slug)
                )
                if not existing.scalar_one_or_none():
                    antonym_list = VocabularyList(
                        title="Antonyme (Gegenteile)",
                        title_arabic="Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯",
                        slug=slug,
                        description="Arabische Wortpaare mit gegensÃ¤tzlicher Bedeutung",
                        word_type=WordType.NOUN,
                        level=VocabularyLevel.A2,
                        is_published=True,
                        item_count=len(antonyms) * 2,
                        tags=["antonyme", "gegenteile", "adjektive"],
                    )
                    session.add(antonym_list)
                    await session.flush()
                    
                    for idx, ant in enumerate(antonyms):
                        # Erstes Wort
                        item1 = VocabularyItem(
                            vocabulary_list_id=antonym_list.id,
                            arabic=ant["arabic"],
                            arabic_voweled=ant["arabic"],
                            german=ant["german"],
                            word_type=WordType.NOUN,
                            notes=f"Gegenteil: {ant['opposite']} ({ant['oppositeGerman']})",
                            order=idx * 2 + 1,
                            difficulty=2,
                            is_verified=True,
                        )
                        session.add(item1)
                        
                        # Gegenteil
                        item2 = VocabularyItem(
                            vocabulary_list_id=antonym_list.id,
                            arabic=ant["opposite"],
                            arabic_voweled=ant["opposite"],
                            german=ant["oppositeGerman"],
                            word_type=WordType.NOUN,
                            notes=f"Gegenteil: {ant['arabic']} ({ant['german']})",
                            order=idx * 2 + 2,
                            difficulty=2,
                            is_verified=True,
                        )
                        session.add(item2)
                        items_created += 2
                    
                    lists_created += 1
                    print(f"  âœ… Antonyme-Liste mit {len(antonyms) * 2} WÃ¶rtern erstellt")
                else:
                    print("  â­ï¸  Antonyme-Liste existiert bereits, Ã¼berspringe...")
            
            await session.commit()
            
            print("\n" + "=" * 50)
            print(f"âœ… Seed abgeschlossen!")
            print(f"   ğŸ“š {lists_created} Listen erstellt")
            print(f"   ğŸ“ {items_created} Vokabeln erstellt")
            print("=" * 50)
            
        except Exception as e:
            await session.rollback()
            print(f"âŒ Fehler beim Seeding: {e}")
            raise


def run_seed():
    """FÃ¼hrt das Seeding aus"""
    print("\nğŸŒ± Starte Vokabel-Seeding...")
    print("=" * 50)
    asyncio.run(seed_vocabulary())


if __name__ == "__main__":
    # FÃ¼ge das Ã¼bergeordnete Verzeichnis zum Python-Pfad hinzu
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    
    run_seed()

